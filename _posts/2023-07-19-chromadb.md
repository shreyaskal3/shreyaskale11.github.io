---
title: Case Study on Prompt Engineering for Job Type Classification
date: 2023-07-19 00:00:00 +0800
categories: [Blogging, Tutorial]
tags: [favicon]
---


The task of job classification refers to the process of determining whether an English-language job posting is appropriate for a graduate or entry-level position. This task involves analyzing the language used in job postings and identifying subtle signals of a job's suitability. 


Large Language Models (LLMs) have the potential to revolutionize the workplace by automating many tasks that currently require human intervention. LLMs can be used for a wide range of applications, including natural language processing, text classification, and machine translation. In the context of job classification, LLMs can be used to filter out non-graduate jobs and identify suitable job postings for job-seekers. By leveraging the vast amounts of knowledge acquired during their training, LLMs can outperform traditional models and achieve impressive results with minimal fine-tuning.

Data Our target task is Graduate Job Classification. It is a binary classification, where, given a job posting containing both the job title and its description,
the model must identify whether or not the job is a position fit for a recent
graduate or not, either because it requires more experience or doesnâ€™t require
higher education. In practice, over 25,000 jobs are received on a daily basis, with
fewer than 5% of those appropriate for graduates.

- Support Vector Machine (SVM) classifier with tf-idf representation:

    Use an SVM classifier, a popular non-deep learning method, for job classification.
Represent the text using the tf-idf (term frequency-inverse document frequency) technique, which assigns weights to words based on their frequency and rarity in the dataset.
Train the SVM classifier on the tf-idf representations of the job postings.
This approach has shown robust baseline results and can achieve state-of-the-art performance in domain-specific tasks.

* ULMFiT (Universal Language Model Fine-tuning):

Pre-train a small language model (such as an RNN-based model) on an unlabeled dataset of 50,000 job postings.
    Fine-tune the pre-trained language model for the specific classification task described above.
    ULMFiT uses transfer learning by leveraging the knowledge learned during pre-training to improve the performance of the classification task.

```python
from fastai.text import *

# Assuming you have preprocessed data, where 'X' is the list of job postings and 'y' is the corresponding labels

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a DataFrame for the training and testing data
train_df = pd.DataFrame({'text': X_train, 'label': y_train})
test_df = pd.DataFrame({'text': X_test, 'label': y_test})

# Create a TextDataBunch for the language model and classifier
data_lm = TextDataBunch.from_df('.', train_df=train_df, valid_df=test_df, text_cols='text')
data_clas = TextClasDataBunch.from_df('.', train_df=train_df, valid_df=test_df, text_cols='text', label_cols='label', vocab=data_lm.train_ds.vocab)

# Pretrain a language model
learn_lm = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)
learn_lm.fit_one_cycle(1, 1e-2)

# Save the pretrained language model encoder
learn_lm.save_encoder('lm_encoder')

# Fine-tune the language model for classification
learn_clas = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)
learn_clas.load_encoder('lm_encoder')
learn_clas.fit_one_cycle(1, 1e-2)

# Evaluate the classifier's performance
learn_clas.validate()

# Predict the labels for new job postings
preds, _ = learn_clas.get_preds(DatasetType.Test)
predicted_labels = preds.argmax(dim=-1)

# Perform any necessary post-processing or evaluation on the predicted labels

```
In this code, the fastai library is used to create a TextDataBunch for the language model and classifier. The TextDataBunch class takes care of tokenizing the text data, creating a vocabulary, and preparing the data for training and inference. The TextClasDataBunch is specifically used for classification tasks.

The code starts by splitting the data into training and testing sets and creating DataFrames for both sets. Then, a language model and a classifier are created using the language_model_learner and text_classifier_learner functions, respectively. The language model is pretrained on the unlabeled dataset using the fit_one_cycle method, and the encoder (pretrained weights) of the language model is saved.

Next, the classifier is loaded with the pretrained encoder and fine-tuned for the specific classification task using the fit_one_cycle method. The performance of the classifier is validated using the validate method.

Finally, the trained classifier is used to predict the labels for new job postings using the get_preds method. The predicted labels can then be further processed or evaluated as per your requirements.

Please note that this code assumes you have the preprocessed data in the form of lists 'X' (job postings) and 'y' (labels). You may need to adapt it to your specific dataset and preprocessing pipeline. Additionally, you can experiment with different hyperparameters, such as the learning rate (1e-2 in this example), to optimize the performance of the ULMFiT model for your job classification task.

* DeBERTa-V3:

    Fine-tune a DeBERTa-V3-Base model, which is an improved version of the DeBERTa model.
DeBERTa-V3 is a state-of-the-art model that achieves excellent performance on various text classification tasks.
Follow the method used in the paper introducing the model, including a maximum sequence length of 512 tokens.
For longer documents, use the first 100 tokens and the trailing 412 tokens to report results. This approach is based on the observation that job descriptions often outline requirements towards the end.
```python
from transformers import DebertaTokenizer, DebertaForSequenceClassification
from torch.utils.data import DataLoader
import torch

# Assuming you have preprocessed data, where 'X' is the list of job postings and 'y' is the corresponding labels

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Load the DeBERTa tokenizer
tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-v3-base')

# Tokenize the input data
train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=512)
test_encodings = tokenizer(X_test, truncation=True, padding=True, max_length=512)

# Convert the labels to tensors
train_labels = torch.tensor(y_train)
test_labels = torch.tensor(y_test)

# Create a PyTorch DataLoader for the training and testing sets
train_dataset = torch.utils.data.TensorDataset(train_encodings.input_ids, train_encodings.attention_mask, train_labels)
test_dataset = torch.utils.data.TensorDataset(test_encodings.input_ids, test_encodings.attention_mask, test_labels)
train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)

# Load the DeBERTa model for sequence classification
model = DebertaForSequenceClassification.from_pretrained('microsoft/deberta-v3-base', num_labels=2)

# Set the maximum sequence length to 512 tokens
model.config.max_position_embeddings = 512

# Fine-tune the DeBERTa model
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)

for epoch in range(3):  # Fine-tune for 3 epochs
    model.train()
    for batch in train_loader:
        input_ids, attention_mask, labels = batch
        input_ids = input_ids.to(device)
        attention_mask = attention_mask.to(device)
        labels = labels.to(device)
        
        optimizer.zero_grad()
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        loss.backward()
        optimizer.step()
        
    model.eval()
    total_correct = 0
    total_samples = 0
    with torch.no_grad():
        for batch in test_loader:
            input_ids, attention_mask, labels = batch
            input_ids = input_ids.to(device)
            attention_mask = attention_mask.to(device)
            labels = labels.to(device)
            
            outputs = model(input_ids, attention_mask=attention_mask)
            logits = outputs.logits
            predicted_labels = torch.argmax(logits, dim=1)
            
            total_correct += (predicted_labels == labels).sum().item()
            total_samples += labels.size(0)
    
    accuracy = total_correct / total_samples
    print(f"Epoch {epoch+1}: Accuracy = {accuracy}")

# Predict the labels for new job postings
new_job_postings = [...]  # List of new job postings
new_encodings = tokenizer(new_job_postings, truncation=True, padding=True, max_length=512)
new_dataset = torch.utils.data.TensorDataset(new_encodings.input_ids, new_encodings.attention_mask)
new_loader = DataLoader(new_dataset, batch_size=8, shuffle=False)

model.eval()
predictions = []
with torch.no_grad():
    for batch in new_loader:
        input_ids, attention_mask = batch
        input_ids = input_ids.to(device)
        attention_mask = attention_mask.to(device)
        
        outputs = model(input_ids, attention_mask=attention_mask)
        logits = outputs.logits
        predicted_labels = torch.argmax(logits, dim=1)
        
        predictions.extend(predicted_labels.cpu().tolist())

# Perform any necessary post-processing or evaluation on the predictions

```
In this code, the Hugging Face Transformers library is used to load the DeBERTa-V3-Base model and tokenizer. The input data is tokenized using the tokenizer, and the labels are converted to PyTorch tensors. Then, PyTorch DataLoaders are created for the training and testing sets.

The DeBERTa model for sequence classification is loaded and fine-tuned for the job classification task. The maximum sequence length is set to 512 tokens as specified in the paper. The model is trained for a specified number of epochs, and the accuracy is computed on the test set after each epoch.

After fine-tuning, you can use the model to predict the labels for new job postings. The new job postings should be provided as a list, and their corresponding labels will be predicted using the trained model. You may perform any necessary post-processing or evaluation on the predicted labels based on your specific requirements.

Please note that this code assumes you have the preprocessed data in the form of lists 'X' (job postings) and 'y' (labels). You need to modify the code to suit your dataset and preprocessing pipeline. Additionally, you can experiment with different hyperparameters, such as learning rate and batch size, to optimize the performance of the DeBERTa-V3-Base model for your job classification task.

- GPT-3.5 (text-davinci-002&text-davinci-003):

    Use two variants of GPT-3, namely davinci-002 and davinci-003.
These models are large language models (LLMs) that have been trained to improve their ability to follow natural language instructions.
GPT-3.5 models provide results based on deterministic output (temperature 0), favoring the highest probability token in all cases.

- GPT-3.5-turbo (gpt-3.5-turbo-0301):

    Evaluate GPT-3.5-turbo, which is optimized for chat-like interactions.
Modify prompts to fit the conversation-like inputs expected by the model.
GPT-3.5-turbo is the focus of the paper's prompt engineering exploration.

RESEARCH PAPER: https://arxiv.org/pdf/2303.07142.pdf


